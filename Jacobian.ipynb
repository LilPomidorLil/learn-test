{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd45d819",
   "metadata": {},
   "source": [
    "# Jacobian matrix.\n",
    "\n",
    "В этой тетрадке будет рассмотрена матрица Якоби, или Якобиан. \n",
    "\n",
    "__Зачем?__\n",
    "\n",
    "Потому что в нейросетке, которую я сейчас пишу, она очень активно применяется при подсчетах метода обратного распространения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c73fb8",
   "metadata": {},
   "source": [
    "![Собственно Якоби](img/jacobi.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7c329",
   "metadata": {},
   "source": [
    "Начнем с разбора примера __SoftMax Activation Function.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bee8d",
   "metadata": {},
   "source": [
    "__Softmax__ объявляется следующим образом:\n",
    "\n",
    "$$y = softmax(x) = f(x) = \\frac{e^{x_i}}{\\sum_{i=1}^{n} e^{x_i}}$$\n",
    "\n",
    "Предположим, что __x__ это:\n",
    "\n",
    "$$x = \n",
    "\\begin{pmatrix}\n",
    "  x_1 \\\\\n",
    "  x_2 \\\\\n",
    "  x_3 \\\\\n",
    "  x_4 \\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Тогда __y__ задается следующим образом:\n",
    "\n",
    "$$y = \n",
    "\\begin{pmatrix}\n",
    "  y_1 \\\\\n",
    "  y_2 \\\\\n",
    "  y_3 \\\\\n",
    "  y_4 \\\\\n",
    "\\end{pmatrix}\n",
    "= softmax(x) = f(x) =\n",
    "\\begin{pmatrix}\n",
    "\\frac{e^{x_1}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\frac{e^{x_2}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\frac{e^{x_3}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\frac{e^{x_4}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Что в свою очередь можно представить так:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\frac{e^{x_1}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\frac{e^{x_2}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\frac{e^{x_3}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\frac{e^{x_4}}{e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4}}\\\\\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "  e^{x_1} \\\\\n",
    "  e^{x_2} \\\\\n",
    "  e^{x_3} \\\\\n",
    "  e^{x_4} \\\\\n",
    "\\end{pmatrix} / (e^{x_1} + e^{x_2} + e^{x_3} + e^{x_4})$$\n",
    "\n",
    "__Запрограммируем это.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1f1d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2a00833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "528c46eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.14656488],\n",
       "       [3.97742237],\n",
       "       [4.00675282],\n",
       "       [3.85752518]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.normal(4, 0.1, size = (4, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0df10ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28877591],\n",
       "       [0.24383908],\n",
       "       [0.25109691],\n",
       "       [0.2162881 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d1319a",
   "metadata": {},
   "source": [
    "Грубо говоря Якобиан это матричный набор частных производных.\n",
    "\n",
    "А у нас ситуация такая:\n",
    "\n",
    "$$\n",
    "y_1 = f(x_1, x_2, x_3, x_4) \\\\\n",
    "y_2 = f(x_1, x_2, x_3, x_4) \\\\\n",
    "y_3 = f(x_1, x_2, x_3, x_4) \\\\\n",
    "y_4 = f(x_1, x_2, x_3, x_4) \\\\\n",
    "$$\n",
    "\n",
    "Отсюда мы получаем, что:\n",
    "\n",
    "$$\n",
    "J = \\frac{\\partial (y_1, y_2, y_3, y_4) }{\\partial (x_1, x_2, x_3, x_4)} =\n",
    "\\begin{pmatrix}\n",
    "  \\frac{\\partial y_1}{\\partial x_1} & \\frac{\\partial y_1}{\\partial x_2} & \\frac{\\partial y_1}{\\partial x_3} &    \\frac{\\partial y_1}{\\partial x_4} \\\\\n",
    "  \\frac{\\partial y_2}{\\partial x_1} & \\frac{\\partial y_2}{\\partial x_2} & \\frac{\\partial y_2}{\\partial x_3} &    \\frac{\\partial y_2}{\\partial x_4} \\\\\n",
    "  \\frac{\\partial y_3}{\\partial x_1} & \\frac{\\partial y_3}{\\partial x_2} & \\frac{\\partial y_3}{\\partial x_3} &    \\frac{\\partial y_3}{\\partial x_4} \\\\\n",
    "  \\frac{\\partial y_4}{\\partial x_1} & \\frac{\\partial y_4}{\\partial x_2} & \\frac{\\partial y_4}{\\partial x_3} &    \\frac{\\partial y_4}{\\partial x_4} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Расписав значения, мы получим, что:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_1}{\\partial x_1} = y_1(1 - y_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_1}{\\partial x_2} = -y_1y_2\n",
    "$$\n",
    "\n",
    "И так далее...\n",
    "\n",
    "__После того как мы найдем все значения, то мы получим следующую матрицу:__ \n",
    "\n",
    "$$\n",
    "J = \n",
    "\\begin{bmatrix}\n",
    "y_1(1 - y_1) & -y1y2 & -y1y3 & -y1y4 \\\\\n",
    "-y1y2 & y_2(1 - y_2) & -y2y3 & -y2y4 \\\\\n",
    "-y1y3 & -y2y3 & y_3(1 - y_3) & -y3y4 \\\\\n",
    "-y1y4 & -y2y4 & -y3y4 & y_4(1 - y_4) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Сделаем следующие упрощения:\n",
    "\n",
    "$$\n",
    "J = \n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "y_4 \\\\\n",
    "\\end{bmatrix} \n",
    "*\n",
    "\\begin{bmatrix}\n",
    "1 - y_1 & -y2 & -y3 & -y4 \\\\\n",
    "-y1 & (1 - y_2) & -y3 & -y4 \\\\\n",
    "-y1 & -y2 & (1 - y_3) & -y4 \\\\\n",
    "-y1 & -y2 & -y3 & (1 - y_4) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "И наконец мы __получаем__:\n",
    "\n",
    "$$\n",
    "J = \n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "y_4 \\\\\n",
    "\\end{bmatrix} \n",
    "*\n",
    "\\Bigg(\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "- \n",
    "\\begin{bmatrix}\n",
    "y_1 & y_2 & y_3 & y_4\n",
    "\\end{bmatrix} \n",
    "\\Bigg)\n",
    "$$\n",
    "\n",
    "Если это записать в классическом виде, то мы получим, что:\n",
    "\n",
    "$$\n",
    "J = softmax(x) * (E - softmax(x).T)\n",
    "$$\n",
    "\n",
    "Теперь осталось все это запрограммировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dd91690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_jacobian(x):\n",
    "    E = np.eye(x.shape[0])\n",
    "    \n",
    "    return softmax(x) * (E - softmax(x).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dbc6dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20538439, -0.07041485, -0.07251074, -0.06245879],\n",
       "       [-0.07041485,  0.18438158, -0.06122724, -0.05273949],\n",
       "       [-0.07251074, -0.06122724,  0.18804725, -0.05430927],\n",
       "       [-0.06245879, -0.05273949, -0.05430927,  0.16950756]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_jacobian(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e2db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
